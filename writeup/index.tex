\documentclass{article}
\usepackage{graphicx} 
% \usepackage[UTF8]{ctex}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath,amsthm,color}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{MnSymbol}
% \usepackage{cite}
\usepackage[style=apa]{biblatex}
\addbibresource{reference.bib}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\theoremstyle{definition}
\newtheorem{example}{Example}
% \theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{proof of proposition}{Proof of Proposition}

\title{Outline}
\author{Yihui He}
\date{Sep 2023}
\begin{document}
\maketitle
\setup
\section{Introduction}

In traditional causal models, the exposure variable W is set to be a binary variable, which represents whether or not the unit is in the treated group of the policy of interest. There, we focus on the potential outcomes corresponding to $W=0$ and $W=1$. However, we can also set the exposure variable to be a continuous random vector. In this case, we investigate the main mediating variables between the policy and the outcomes of interest, such as PM2.5 and CO level in air pollution field. These factors are used as the exposure variable, as in \cite{munoz2012population}. Here, we analyze the potential outcomes corresponding to $W=d$, where d is an arbitrary vector. 

Compared with traditional models, such a causal model can not only help us interpret the effect of a past policy, but it also helps us predict the effect of a future policy. After all, a future policy often has different policy goals from a past one, and the indicator variables of the two policies may have totally different meanings.  With continuous causal model, however, we obtain the dose-response curve of a policy. From this curve, we know how a policy's causal effect on outcomes changes with its effect on mediating variables. Then, we can evaluate a future policy as long as we know how much it expects to influence mediating variables. Furthermore, if we can estimate how the cost of the policy changes with the extent to which the policy changes the mediating variables, we can do a "global" benefit-cost analysis and set an optimal policy goal about the mediating variables, making the budget most efficient.

In this article, we can consider the evaluation of an air pollution policy. Suppose the policy only changes the concentration of pollutants in the air. Taking each area as a unit, we can set the levels of the pollutants there as W, set an indicator of public health there as Y, and set sufficiently many covariates not influenced by the policy as X, including age distribution, living habits and climate in the target area, etc. Following \cite{pearl2000models}, we can set the non-parametric structural equation model as follows: 
\begin{align}
    X = f_X(U_X);\ W = f_W(X, U_W );\ Y = f_Y (W, X, U_Y )
\end{align} 
where  $U_{X}$, $U_{W}$ and  $U_{Y}$  are exogenous random variables such that  $U_{W}$ is independent of $ U_{Y}$, and $U_{X}$ is independent of $ U_{Y}$ or $U_{W}$. In our setting, the policy only influences the second equation, keeping $U_{X}$ and $U_{Y}$ constant. Therefore, we can define the potential outcome as
\begin{equation}
    Y(\mathbf{w}) = f_Y (\mathbf{w}, X, U_Y)
\end{equation}
It's worth noting that in this model we do not require any past policy to be implemented. We expect to use observational data from one time period.

Suppose the policy turns the exposure variable of each treated unit from W to $W^{\mathbf{d}}=T(W;\mathbf{d})$, where T is an operator and $\mathbf{d}$ is a vector representing the intensity of the policy. For example, an air-quality improvement policy may have the following influence on the exposure variable:
\begin{align}
    T_1(W;\mathbf{d})&=W-\mathbf{d}\\
    T_2(W;\mathbf{d})&=(W_1(1-d_1),\cdots, W_{k_w}(1-d_{k_w}))
\end{align}
Reasonably, we denote $Y(T(W;\mathbf{d}))-Y$ as the causal effect of the future policy with intensity $\mathbf{d}$. When we construct the dose-response curve, we keep T constant and estimate the causal effect corresponding to policy with different d-value.

The key estimand in our model is based on the stochastic intervention causal parameter in \cite{munoz2012population}, with the form of:
\begin{align}
    \theta(\mathbf{d})=E_{(W,X)\in \mathcal{D}_0}[Y(T(W;\mathbf{d}))-Y] 
\end{align}
where $\mathcal{D}_0$ is a given domain. For simplicity, we'll use $\theta$ instead of $\theta(\mathbf{d})$ below. 

In this article, we develop several methods to estimate $\theta$ based on bias corrected matching in \cite{abadie2011bias}, because bias-corrected matching can not only achieve root-n consistency but also output more stable result than weighting methods in \cite{munoz2012population}. We modify nearest neighbor matching, generalized propensity score (GPS) matching, random forest method proposed in \cite{lin2022regression} and double machine learning method proposed in \cite{lin2021estimation} to establish bias-corrected matching estimators respectively. Here, nearest neighbor matching is used because of its good theoretical properties; GPS matching is used because it can solve the problem of high-dimensional covariates; random forest is used because of its well-known good practical performance; double machine learning is used because of its flexible regression model. In our data simulations, we make comparisons among the four estimators and the TMLE estimator in \cite{mccoy2023semi}. 

Although the matching methods above can estimate $\theta$ for arbitrary $(\mathbf{w},\mathbf{x},\mathbf{d})$, some of the estimates are invalid. Obviously, to meet the overlap assumption in causal inference, $(W,X)$'s support $\mathcal{D}$ has to be a finite-measure set in the space instead of the whole space. Therefore, $(T(\mathbf{w};\mathbf{d}),\mathbf{x})$ would fall on the outside of $\mathcal{D}$ for some $(\mathbf{w},\mathbf{x},\mathbf{d})$, and in such a condition we don't even have a valid definition of $Y(T(\mathbf{w};\mathbf{d}))$. To avoid this problem, we recommend the researchers to set $\mathcal{D}_0$ as a sufficiently small subset of $\mathcal{D}$. Inspired by \cite{mccoy2023semi}, we can use the probability density ratio estimator in \cite{lin2021estimation} to estimate $\frac{p(\mathbf{w},\mathbf{x})}{p(T(\mathbf{w};\mathbf{d}),\mathbf{x})}$. And $\mathcal{D}_0$ can be the set in which the probability density ratio estimator is less than 50.

Our methods are meaningful to the field of public health. Although continuous causal inference is more and more common in air pollution field nowadays, our methods are among the earliest literature to discuss high-dimensional exposure. Actually, we're always exposed to a mixture of exposures that jointly influence our health in a non-additive way. For example, the elemental carbon, organic carbon compounds, sulfate, nitrate, ammonium salt and metals in PM 2.5 may well synergize or antagonize the effect of one another in the complex bio-chemical mechanisms within our body. However, for a policy that reduces the concentration of the pollutants simultaneously, most epidemiological researches nowadays, such as \cite{xiao2021cadmium} and \cite{meng2021short}, still simply add up the effect of each pollutant's reduction to estimate the overall effect of the policy. Our methods can help them better deal with the non-additive non-linear effect of the exposures. 

We apply our methods to the air pollution data $\cdots$

This article is organized as follows. In Section 2 we describe the setup and the assumptions of our model in detail. In Section 3 we describe the procedure and the theoretical properties of our bias-corrected matching estimators, which is the main analysis part of the article. In Section 4 we discuss the use of some methods in previous public health literature about causal mixture model to complement our matching estimators. In Section 5 we do data simulations to see the practical performance of our methods and traditional TMLE methods. In Section 6 we apply our methods to the data of xxx and calculate the best air pollution policy for xxx city. In Section 7 we conclude our findings.
\section{Setup}
\begin{assumption}
(i) Without policy intervention, $X \in R^{k_x}$, $W \in R^{k_w}$ and $Y \in R^{k_y}$ are continuously distributed; (ii) The structural equation model is $X = f_X(U_X)$, $W = f_W(X, U_W)$ and $Y = f_Y (W, X, U_Y )$, where  $U_{X}$, $U_{W}$ and  $U_{Y}$  are exogenous random variables. (iii) $U_{W}$ is independent of $ U_{Y}$, and $U_{X}$ is independent of $ U_{Y}$ or $U_{W}$. (iv) The policy of interest only affect $U_{W}$, keeping $U_{X}$ and $ U_{Y}$ constant.
\end{assumption}
We let $Y(w)=f_Y(w,X,U_Y)$ be the random variable of the potential outcome of $W=w$. 
About the support of the original exposure and the counterfactual exposure given $T(\cdot;d)$, we make the following assumptions:

\begin{assumption}
(i) The support of (W,X), $\mathcal{D}$, is a Cartesian product of compact intervals; (ii) The population treated by the policy are the units whose $(W_i,X_i)$ are in $\mathcal{D}_0$, a known sub-region of $\mathcal{D}$; (iii)$(W,X) \in \mathcal{D}_0\Rightarrow (T(W;d),X)\in \mathcal{D}$.
\end{assumption}

\begin{remark} (i) in Assumption 2 is the requirement of series regression in bias-corrected matching. This assumption is quite technical, so our results may still be valid even if it's violated. Besides, in GPS matching section, we weaken the assumtion.
\end{remark}

Also, we define the multi-variate generalized propensity score (mvGPS) as follows:
\begin{align}
    e(\mathbf{w}|\mathbf{x}) &= p(W=\mathbf{w}|X=\mathbf{x})
\end{align}
As in regular causal inference, we make the overlap assumption:

\begin{assumption}
$e(\mathbf{w}|\mathbf{x})>\eta$ holds for any $(\mathbf{w},\mathbf{x}) \in \mathcal{D}$, where $\eta>0$ is an absolute constant.
\end{assumption}

\begin{remark} 
Under Assumption 3, $\mathcal{D}$ is of bounded measure. Therefore, it's reasonable to limit $\mathcal{D}_0$ to a sub-region of $\mathcal{D}$ in Assumption 2 in order to avoid the condition $(T(W;d),X) \notin \mathcal{D}$.
\end{remark}

\begin{assumption} 
Let $\mu(\mathbf{w},\mathbf{x})=\mathbb{E}\left[Y|W=\mathbf{w}, X=\mathbf{x}\right]$  and  $\sigma^{2}(\mathbf{w},\mathbf{x})=\mathbb{E}\left[\left(Y-\mu(\mathbf{w},\mathbf{x})\right)^{2} \mid W=\mathbf{w} ,X=\mathbf{x}\right]$. Then, (i) $\mu(\mathbf{w},\mathbf{x})$  and  $\sigma^{2}(\mathbf{w},\mathbf{x})$ are Lipschitz continuous in $\mathcal{D}$, (ii)  $\mathbb{E}[(Y(\mathbf{w}))^{4}|X=\mathbf{x}] \leq C$  for some finite  C , for almost all $\mathbf{x}$, and (iii)  $\sigma^{2}(\mathbf{w},\mathbf{x})$  is bounded away from zero.
\end{assumption}

\begin{lemma} 
\begin{align}
E\left[Y(T(W))|(W,X) \in \mathcal{D}_0\right]=E\left[Y\frac{e(T^{-1}(W)|X)}{e(W|X)}|(W,X) \in \mathcal{D}_1\right]
\label{identification}
\end{align}
\end{lemma}

\begin{lemma} 
Suppose $(\tilde{W},\tilde{X})$ is of the same distribution of $(W,X)$, then
\begin{align}
E[Y(T(W))|(W,X) \in \mathcal{D}_0]=E\left[E\left[Y|W=T(\tilde{W}),\frac{e(W,X)}{e(T^{-1}(W),X)}=\frac{e(T(\tilde{W}),\tilde{X})}{e(\tilde{W},\tilde{X})}\right]\mid (\tilde{W},\tilde{X})\in\mathcal{D}_1\right]
\end{align}
\end{lemma}
Let $\mathcal{D}_1=\{(T(W;\mathbf{d}),X)|(W,X) \in \mathcal{D}_0\}$.  In our article, the parameter of interest is 
\begin{align}
    a\theta=E[]
\end{align}
$$\hat{\theta}_{bc}=\frac{1}{N_0}\sum\limits_{i \in \mathcal{D}_0}(Y_{m(i)}+\hat{\mu}(T(W_i),X_i)-\hat{\mu}(W_{m(i)},X_{m(i)}))$$
$$\theta_{bc}=\frac{1}{N_0}\sum\limits_{i \in \mathcal{D}_0}(Y_{m(i)}+\hat{\bar{\mu}}(T(W_i),\hat{r}(T(W_i),X_i))-\hat{\bar{\mu}}(W_{m(i)},\hat{r}(W_{m(i)},X_{m(i)})))$$
$$\psi(O;\theta,\mu,r)=(Y-\mu(W,X))r(W,X)+\mu(T(W),X)-\theta$$
$$\psi(O;\theta,\bar{\mu},r)=(Y-\bar{\mu}(W,r(W,X)))r(W,X)+\bar{\mu}(T(W),r(T(W),X))-\theta$$
\begin{theorem}
    s
\end{theorem}
\end{document}